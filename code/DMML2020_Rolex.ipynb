{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚åöÔ∏è DM&ML 2020 - Team Rolex\n",
    "\n",
    "## üñã Authors\n",
    "- Francis Ruckstuhl, 16-821-738\n",
    "- Hanna Birbaum, 16-050-114\n",
    "- Lo√Øc Rouiller-Monay, 16-832-453\n",
    "\n",
    "## üïµÔ∏è Project description\n",
    "\n",
    "Real or Not? NLP with Disaster Tweets: Machine Learning model that can predict which tweets are about a real disaster and which are not. The project topic is based around a Kaggle competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## üìù Commits\n",
    "\n",
    "### Best commit:\n",
    "\n",
    "**Commit 2 : 0.818%**\n",
    "- data cleaning : remove unicode literals, urls, link, author, hashtags, rt\n",
    "- feature engineering : num_chars, num_words, avg_words\n",
    "- BOW\n",
    "- LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "### [B.] Previous commits\n",
    "\n",
    "**Commit 1 : 0.808%**\n",
    "- spacy_tokenizer: remove stopwords, punctuation, numbers then lemmatize and lowercase\n",
    "- TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), tokenizer=spacy_tokenizer)\n",
    "- LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "**Commit 2 : 0.818%**\n",
    "- data cleaning : remove unicode literals, urls, link, author, hashtags, rt\n",
    "- feature engineering : num_chars, num_words, avg_words\n",
    "- BOW\n",
    "- LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "**Commit 3 : 0.809%**\n",
    "- data cleaning : remove unicode literals, urls, link, author, hashtags, rt, punctuations, lowercase\n",
    "- feature engineering : num_chars, num_words, avg_words, num_hashtags\n",
    "- BOW\n",
    "- LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "**Commit 4 : 0.801%**\n",
    "- data cleaning : remove unicde literals, urls, link, author, hashtags, rt, punctuations, lowercase, lemmatize, stemming\n",
    "- model_dbow = Doc2Vec(dm=0, vector_size=30, negative=6, hs=0, min_count=1, sample=0, workers=cores, epoch=300)\n",
    "- Word2Vec\n",
    "- LogisticRegression(max_iter=1000, solver='lbfgs')\n",
    "\n",
    "**Commit 5 : 0.812%**\n",
    "- Same as Commit 4 but without stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###¬†[C.] Progression of accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /!\\ You have to run Chapter 1. \"libraries‚Äú first before being able to plot the progression of accuracies\n",
    "accuracy_progression = pd.read_csv('../documents/accuracy_progression.csv', sep=';')\n",
    "sns.lineplot(x=accuracy_progression.commit_number, y=accuracy_progression.accuracy, linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìö 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "import spacy\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "# load English language model of spacy\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "import string\n",
    "from spellchecker import SpellChecker\n",
    "import pycountry\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from gensim.models.doc2vec import TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yet to discuss whether this will be used or not\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìÇ 2. Download data\n",
    "\n",
    "\n",
    "## Files\n",
    "- train.csv - the training set\n",
    "- test.csv - the test set\n",
    "- sample_submission.csv - a sample submission file in the correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/training_data.csv')\n",
    "test = pd.read_csv('../data/test_data.csv')\n",
    "sample_submission = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "- id - a unique identifier for each tweet\n",
    "- text - the text of the tweet\n",
    "- location - the location the tweet was sent from (may be blank)\n",
    "- keyword - a particular keyword from the tweet (may be blank)\n",
    "- target - in train.csv only, this denotes whether a tweet is about a real disaster (1) or not (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî¨ 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [A.] What is the baserate of the problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_rate = train.target.value_counts().max()/len(train)\n",
    "print(f'\\nThe base rate is {base_rate}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##¬†Target class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"target\", kind=\"count\", data=train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It misses value in two features : keyword and location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing value in \"keyword\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.keyword.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing value in \"location\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.location.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"num_char\"] = train[\"text\"].apply(len)\n",
    "test[\"num_char\"] = test[\"text\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='target', y='num_char', data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Findings\n",
    "Tweets about real disaster seems to be lengthier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"num_words\"] = train[\"text\"].apply(lambda x: len(x.split()))\n",
    "test[\"num_words\"] = test[\"text\"].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='target', y='num_words', data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Findings\n",
    "Tweets about real disaster do not seem to have more words. Maybe it'll help to take this into consideration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"avg_word_length\"] = train['text'].apply(lambda x: np.sum([len(w) for w in x.split()]) / len(x.split()))\n",
    "test[\"avg_word_length\"] = test['text'].apply(lambda x: np.sum([len(w) for w in x.split()]) / len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='target', y='avg_word_length', data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Findings\n",
    "Tweets about real disaster seems to have lengtier average word length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of hashtags in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['num_hashtags'] = train['text'].apply(lambda x: x.count('#'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='target', y='num_hashtags', data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DISCUSS WITH TEAMMATES ###\n",
    "# Replace NaN values with \"Unknown\"? (NaNs need to be replace for label encoding)\n",
    "train[\"keyword\"] = train[\"keyword\"].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding for keywords\n",
    "label = LabelEncoder()\n",
    "keyword_label = pd.Series(label.fit_transform(train[\"keyword\"]), name=\"keyword_code\")\n",
    "keyword_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perhaps display the most frequent keywords? \n",
    "train[\"keyword\"].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disaster Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where do most disasters occur / where do disaster tweets come from? \n",
    "# Potential problem to take care of: USA and United States are separate; Different US States are also separate;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many different locations are there?\n",
    "train[\"location\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regex for countries that require cleaning:\n",
    "\n",
    "# United States:\n",
    "usa_regex = re.compile(r\"\"\"(?i)Alabama|\\bAL\\b|Alaska|\\bAK\\b|Arizona|\\bAZ\\b|Arkansas|\\bAR\\b|California|\\bCA\\b|Colorado|\\bCO\\b|\n",
    "                Connecticut|\\bCT\\b|Delaware|\\bDE\\b|Florida|\\bFL\\b|Georgia|\\bGA\\b|Hawaii|\\bHI\\b|Idaho|\\bID\\b|Illinois|\\bIL\\b|\n",
    "                Indiana|\\bIN\\b|Iowa\\bIA\\b|Kansas|\\bKS\\b|Kentucky|\\bKY\\b|Louisiana|\\bLA\\b|Maine|\\bME\\b|Maryland|\\bMD\\b|Massachusetts|\n",
    "                \\bMA\\b|Michigan|\\bMI\\b|Minnesota|\\bMN\\b|Mississippi|\\bMS\\b|Missouri|\\bMO\\b|Montana|\\bMT\\b|Nebraska|\\bNE\\b|Nevada|\n",
    "                \\bNV\\b|New\\sHampshire|\\bNH\\b|New\\sJersey|\\bNJ\\b|New Mexico|\\bNM\\b|New\\sYork|\\bNY\\b|\\bNYC\\b|North\\sCarolina|\\bNC\\b|\n",
    "                North\\sDakota|\\bND\\b|Ohio|\\bOH\\b|Oklahoma|\\bOK\\b|Oregon|\\bOR\\b|Pennsylvania|\\bPA\\b|Rhode\\sIsland|\\bRI\\b|South\\sCarolina|\n",
    "                \\bSC\\b|South\\sDakota|\\bSD\\b|Tennessee|\\bTN\\b|Texas|\\bTX\\b|Utah|\\bUT\\b|Vermont|\\bVT\\b|Virginia|\\bVA\\b|Washington|\\bWA\\b|\n",
    "                West\\sVirginia|\\bWV\\b|Wisconsin|\\bWI\\b|Wyoming|\\bWY\\b|\\bUSA\\b|San\\sFrancisco|Los\\sAngeles|Seattle|Chicago|\n",
    "                Atlanta\"\"\", re.VERBOSE)\n",
    "\n",
    "# United Kingdom:\n",
    "uk_regex = re.compile(r\"\"\"(?i)UK|London|England|Scotland|Wales|Birmingham|Glasgow|Liverpool|Bristol|Manchester|\n",
    "                      Sheffield|Leeds|Edinburgh|Leicester|Coventry|Bradford|Cardiff|Belfast|Oxford|Plymouth|Aberdeen\"\"\", re.VERBOSE)\n",
    "\n",
    "# Canada:\n",
    "ca_regex = re.compile(r\"\"\"(?i)Canada|Ontario|Quebec|Nova\\sScotia|New Brunswick|Manitoba|British\\sColumbia|Prince\\sEdward\\sIsland|\n",
    "                      Saskatchewan|Alberta|Newfoundland|Labrator|Toronto|Ottawa|Vancouver|Calgary\"\"\", re.VERBOSE)\n",
    "\n",
    "# Australia:\n",
    "au_regex = re.compile(r\"\"\"(?i)australia|Brisbane|Melbourne|Sydney|Perth|Adelaide|Capital\\sTerritory|Canberra|Hobart|\n",
    "                      Darwin|Gold\\sCoast|Queensland|Victoria|Tasmania\"\"\", re.VERBOSE)\n",
    "\n",
    "# India:\n",
    "in_regex = re.compile(r\"\"\"(?i)mumbai|Maharashtra|Delhi|Kolkata|West\\sBengal|Chennai|Tamil\\sNadu|Hyderabad|Bangalore|\n",
    "                      Ahmedabad|Surat|Jaipur|Kanpur|Nagpur|Gujarat|Uttar\\sPradesh\"\"\", re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the rows and check if any of the locations matches one of our regexes\n",
    "# If so, the entire value will be replaced by a unified name:\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "\n",
    "  # For any location in the United States:\n",
    "  if re.search(usa_regex, str(train.loc[index, \"location\"])):\n",
    "    train.loc[index, \"location\"] = \"United States\"\n",
    "\n",
    "  # For any location in the United Kingdom:\n",
    "  elif re.search(uk_regex, str(train.loc[index, \"location\"])):\n",
    "    train.loc[index, \"location\"] = \"United Kingdom\"\n",
    "\n",
    "  # For any location in Canada:\n",
    "  elif re.search(ca_regex, str(train.loc[index, \"location\"])):\n",
    "    train.loc[index, \"location\"] = \"Canada\"\n",
    "  \n",
    "  # For any location in Australia:\n",
    "  elif re.search(au_regex, str(train.loc[index, \"location\"])):\n",
    "    train.loc[index, \"location\"] = \"Australia\"\n",
    "  \n",
    "  # For any location in the India:\n",
    "  elif re.search(in_regex, str(train.loc[index, \"location\"])):\n",
    "    train.loc[index, \"location\"] = \"India\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the top 5 countries:\n",
    "countries = train[\"location\"].value_counts()\n",
    "countries = countries.sort_values(ascending=False).head(5)\n",
    "countries.plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DISCUSS WITH TEAMMATES ###\n",
    "# Will this help with data cleaning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üßπ 4. Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove '%20' from keyword feature\n",
    "train.keyword = train.keyword.apply(lambda lex: str(lex).replace('%20', ' '))\n",
    "test.keyword = train.keyword.apply(lambda ro: str(ro).replace('%20', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if NaN values in the keyword feature\n",
    "print(train.keyword.isnull().any())\n",
    "print(test.keyword.isnull().any())\n",
    "\n",
    "# There's no null values between the keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pycountry in order to check if a country appears in the location\n",
    "# if yes takes the country, else turn it to NaN\n",
    "# with train and test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.location.apply(lambda x: print(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "punctuations = string.punctuation\n",
    "\n",
    "def separate_punct(text):\n",
    "    temp = []\n",
    "    for char in text:\n",
    "        if char not in punctuations:\n",
    "            temp.append(char)\n",
    "        else:\n",
    "            temp.append(' '+char)\n",
    "    return ''.join(temp)\n",
    "\n",
    "def clean_text(text):\n",
    "    # remove unicode literals\n",
    "    temp = text.encode('ascii',errors='ignore').decode('ascii')\n",
    "    \n",
    "    # remove &amp\n",
    "    temp = temp.replace('&amp;', '')\n",
    "    \n",
    "    # remove urls\n",
    "    temp = re.sub(r\"http\\S+\", \"\", temp)\n",
    "    \n",
    "    # remove html\n",
    "    temp = re.sub(r'<.*?>', \"\", temp)\n",
    "    \n",
    "    # remove hashtags\n",
    "    temp = re.sub(r'#', \"\", temp)\n",
    "\n",
    "    # remove people account with @\n",
    "    temp = re.sub(r'@\\S+', \"\", temp)\n",
    "    \n",
    "    # remove 'RT'\n",
    "    temp = temp.replace('RT', '')\n",
    "    \n",
    "    # remove punctuation\n",
    "    temp = ''.join([ char for char in temp if char not in punctuations ])\n",
    "    \n",
    "    # separate punctuation\n",
    "    # temp = separate_punct(temp)\n",
    "\n",
    "    # remove \".\"\n",
    "    #temp.replace('.','')\n",
    "    \n",
    "    # lowercase\n",
    "    temp = temp.lower()\n",
    "    \n",
    "    # spell checking\n",
    "    spell = SpellChecker()\n",
    "    temp_spellchecked = []\n",
    "    for word in temp.split():\n",
    "        temp_spellchecked.append(spell.correction(word))\n",
    "        \n",
    "    # stemming with nltk\n",
    "    #stemmer = SnowballStemmer(language='english')\n",
    "    #temp_stemmed = []\n",
    "    #for word in temp_spellchecked:\n",
    "    #    temp_stemmed.append(stemmer.stem((word)))\n",
    "    \n",
    "    # create spacy object\n",
    "    temp = sp(' '.join(temp_spellchecked))\n",
    "\n",
    "    # lemmatize each token and convert each token into lowercase\n",
    "    temp = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in temp ]\n",
    "    \n",
    "    # remove stop words \n",
    "    temp = [ word for word in temp if word not in stop_words  ]\n",
    "    \n",
    "    # join\n",
    "    temp = ' '.join(temp)\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# clean text\n",
    "train.text = train.text.apply(lambda x: clean_text(x))\n",
    "test.text = test.text.apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_spellchecked.csv')\n",
    "test.to_csv('test_spellchecked.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train_spellchecked.csv')\n",
    "test = pd.read_csv('../data/test_spellchecked.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.text.apply(lambda x: print(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.location.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üõ† [D.] 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycountry.countries.search_fuzzy('England')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# not good \n",
    "def location_to_country(location):\n",
    "    temp = location.split(',')\n",
    "    countries = list(pycountry.countries)\n",
    "    \n",
    "    for word in temp:\n",
    "        for i in range(len(countries)):\n",
    "            if (word.strip() in countries[i].alpha_2) or (word.strip() in countries[i].alpha_3) or (word.strip() in countries[i].name):\n",
    "                return countries[i].name\n",
    "    return 'Unknown'\n",
    "\n",
    "train['country'] = train.location.apply(lambda x: location_to_country(str(x)))\n",
    "train[['location', 'country']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è 6. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokenizer function for preprocessing\n",
    "def spacy_tokenizer(text):\n",
    "\n",
    "    # Define stopwords, punctuation, rolex and numbers\n",
    "    #stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "    #punctuations = string.punctuation\n",
    "    # numbers = \"0123456789\"\n",
    "\n",
    "    # Create spacy object\n",
    "    mytokens = sp(text)\n",
    "\n",
    "    #Lemmatize each token and convert each token into lowercase\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "\n",
    "    # Remove stop words and punctuation\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "    #\n",
    "    # Remove all word with less that 3 letters (remove noise)\n",
    "    mytokens = [ word for word in mytokens if len(word)>2 ]\n",
    "\n",
    "    # Return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize texts\n",
    "processed_texts = []\n",
    "for text in train.text:\n",
    "    processed_text = spacy_tokenizer(text)\n",
    "    processed_texts.append(processed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ 7. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/training_data_spellchecked.csv')\n",
    "test = pd.read_csv('../data/test_data_spellchecked.csv')\n",
    "sample_submission = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "# change type to string to prevent some errors\n",
    "train.text = train.text.astype(str)\n",
    "train.keyword = train.keyword.astype(str)\n",
    "train.location = train.location.astype(str)\n",
    "\n",
    "test.text = test.text.astype(str)\n",
    "test.keyword = test.keyword.astype(str)\n",
    "test.location = test.location.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll clean this part during the week - Lo√Øc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using default tokenizer \n",
    "count = CountVectorizer(ngram_range=(1,2), stop_words=\"english\")\n",
    "bow = count.fit_transform(train.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names\n",
    "feature_names = count.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show as a dataframe\n",
    "processed_train = pd.DataFrame(\n",
    "    bow.todense(), \n",
    "    columns=feature_names\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features\n",
    "X = processed_train # the features we want to analyze\n",
    "y = train['target'] # the labels, or answers, we want to test against\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifier\n",
    "classifier = LogisticRegressionCV(solver='lbfgs', max_iter=1000, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model on training set\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "print(round(accuracy_score(y_test, y_pred), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW with more additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full = pd.concat([train[['num_char', 'num_words', 'avg_word_length', 'num_hashtags']], processed_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features\n",
    "X = processed_train # the features we want to analyze\n",
    "y = train['target'] # the labels, or answers, we want to test against\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifier\n",
    "classifier = LogisticRegressionCV(solver='lbfgs', max_iter=3000, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fit model on training set\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "print(round(accuracy_score(y_test, y_pred), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW with additional features and Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full = pd.concat([train[['num_char', 'num_words', 'avg_word_length']], processed_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features\n",
    "X = processed_train # the features we want to analyze\n",
    "y = train['target'] # the labels, or answers, we want to test against\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifier\n",
    "classifier = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model on training set\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "print(round(accuracy_score(y_test, y_pred), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features\n",
    "X = train['text'] # the features we want to analyze\n",
    "y = train['target'] # the labels, or answers, we want to test against\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=707)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Define vectorizer\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 1), tokenizer=spacy_tokenizer)\n",
    "\n",
    "# Define classifier\n",
    "classifier = LogisticRegressionCV(solver='lbfgs', max_iter=1000, cv=5)\n",
    "\n",
    "# Create pipeline\n",
    "pipe = Pipeline([('vectorizer', tfidf),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "# Fit model on training set\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "print(round(accuracy_score(y_test, y_pred), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perhaps a random forest? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe try a Random Forest? (- Hanna)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define vectorizer\n",
    "tfidf_vector = TfidfVectorizer(tokenizer=spacy_tokenizer) \n",
    "\n",
    "# Define classifier\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Create pipeline\n",
    "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "# Fit model on training set\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Define vectorizer\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2), tokenizer=spacy_tokenizer)\n",
    "\n",
    "# Define classifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Create pipeline\n",
    "pipe = Pipeline([('vectorizer', tfidf),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "# Fit model on training set\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "print(round(accuracy_score(y_test, y_pred), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using Doc2Vec and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tagged = train.apply(lambda r: TaggedDocument(words=spacy_tokenizer(r['text']), tags=[r.target]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split - same split as before\n",
    "train_tagged, test_tagged = train_test_split(sample_tagged, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows to speed up a bit\n",
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Doc2Vec and build vocabulary\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "model_dbow = Doc2Vec(dm=1, vector_size=100, negative=5, hs=0, min_count=1, sample=0, workers=cores, epoch=500)\n",
    "model_dbow.build_vocab([x for x in train_tagged.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train distributed Bag of Word model\n",
    "model_dbow.train(train_tagged, total_examples=model_dbow.corpus_count, epochs=model_dbow.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select X and y\n",
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=300)) for doc in sents])\n",
    "    return targets, regressors\n",
    "\n",
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)\n",
    "\n",
    "# Each document (i.e. complaint) is now a vector in the space of 30 dimentions.\n",
    "# Similar complaints should have similar vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(cv=9, max_iter=3000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model on training set - same algorithm as before\n",
    "logreg = LogisticRegressionCV(max_iter=3000, cv=9, solver='lbfgs')\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7876\n",
      "cv = 9, basique, clean√© + pays 0.7853\n",
      "0.7869\n",
      "avec cv = 9 :  0.7892\n",
      "avec cv = 9, basique clean:  0.7923\n",
      "avec cv = 9, + features  0.7861\n",
      "avec cv = 9, basique, pas clean [import, token --> c tout] 0.7946\n",
      "avec cv = 10, basique, pas clean [import, token --> c tout] 0.7954\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "print(round(accuracy_score(y_test, y_pred), 4))\n",
    "print('cv = 9, basique, clean√© + pays',0.7853)\n",
    "print(0.7869)\n",
    "print('avec cv = 9 : ', 0.7892)\n",
    "print('avec cv = 9, basique clean: ', 0.7923)\n",
    "print('avec cv = 9, + features ', 0.7861)\n",
    "print('avec cv = 9, basique, pas clean [import, token --> c tout]', 0.7946)\n",
    "print('avec cv = 10, basique, pas clean [import, token --> c tout]', 0.7954)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using Doc2Vec, more features and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÜ 8. Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using default tokenizer \n",
    "count = CountVectorizer(ngram_range=(1,2), stop_words=\"english\")\n",
    "bow = count.fit(train.text)\n",
    "bow = count.transform(train.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names\n",
    "feature_names = count.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show as a dataframe\n",
    "processed_train = pd.DataFrame(\n",
    "    bow.todense(), \n",
    "    columns=feature_names\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full = pd.concat([train[['num_char', 'num_words', 'avg_word_length', 'num_hashtags']], processed_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features\n",
    "X = train_full # the features we want to analyze\n",
    "y = train['target'] # the labels, or answers, we want to test against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifier\n",
    "classifier = LogisticRegressionCV(solver='lbfgs', max_iter=6000, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fit model on training set\n",
    "classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_test = count.transform(test.text)\n",
    "# Get feature names\n",
    "feature_names_test = count.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show as a dataframe\n",
    "processed_test = pd.DataFrame(\n",
    "    bow_test.todense(),\n",
    "    columns=feature_names_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_full = pd.concat([test[['num_char', 'num_words', 'avg_word_length' , 'num_hashtags']], processed_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "\n",
    "y_pred = classifier.predict(test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline\n",
    "pipe = Pipeline([('vectorizer', tfidf),\n",
    "                 ('classifier', classifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(train.text, train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pipe.predict(test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/training_data_spellchecked.csv')\n",
    "test = pd.read_csv('../data/test_data_spellchecked.csv')\n",
    "\n",
    "train[['location', 'text']] = train[['location', 'text']].astype(str)\n",
    "test['target'] = ''\n",
    "test[['location', 'text']] = test[['location', 'text']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tagged = train.apply(lambda r: TaggedDocument(words=spacy_tokenizer(r['text']), tags=[r.target]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tagged = test.apply(lambda r: TaggedDocument(words=spacy_tokenizer(r['text']), tags=[r.target]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows to speed up a bit\n",
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Doc2Vec and build vocabulary\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=30, negative=6, hs=0, min_count=1, sample=0, workers=cores, epoch=300)\n",
    "model_dbow.build_vocab([x for x in train_tagged.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train distributed Bag of Word model\n",
    "model_dbow.train(train_tagged, total_examples=model_dbow.corpus_count, epochs=model_dbow.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select X and y\n",
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=300)) for doc in sents])\n",
    "    return targets, regressors\n",
    "\n",
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegressionCV(max_iter=1000, solver='lbfgs', cv=3)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.target = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('submission-005.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
